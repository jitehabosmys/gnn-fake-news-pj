# 参考链接：https://github.com/safe-graph/GNN-FakeNews
数据获取：https://codeocean.com/capsule/7305473/tree/v1 的data/，下载后放在项目data/

## 题目要求

### 课题3：欺诈检测

#### 任务说明参考
1. **可视化用户之间的社交关系。**
2. **根据用户社交关系、发帖/传播行为、帖子内容等特征，设计一种机器学习模型来识别社交网络中的虚假信息（谣言）、僵尸（虚假）用户，并说明模型的评价方法和识别效果。**
3. **分析僵尸用户和正常用户的社交网络，或真实信息与谣言的传播网络的异同。**

> **补充说明：** 若将一个邮箱地址对应为一个用户，则该任务变成垃圾邮件/邮箱检测。

#### 参考数据集

> *以上所有课题任务皆可自行爬取数据，或从eLearning上参考文献（后续更新）中提供的下载链接下载数据集，相关模型、算法亦可借鉴参考文献。*

#### 附：其他参考资料

- **可视化工具**：Gephi、Echarts、Highcharts、D3、Pajek、NetworkX 等。

---

## 数据集与模型介绍

好的，这个仓库（GNN-FakeNews）是一个基于图神经网络（GNN）的假新闻检测模型合集。下面我将从数据集形式、模型内容以及如何参考使用这三个方面为你详细解读。

### 1. 数据集形式：User Preference-aware Fake News Detection (UPFD)

这个项目的核心是提出了一个名为 **UPFD** 的假新闻检测框架和相应的数据集。

#### 基本概念：
- **任务定义**： 将假新闻检测问题定义为一个**图分类任务**。即，输入一个图，模型需要判断这个图代表的新闻是“真”还是“假”。
- **图的结构**： 每个图都是一棵以新闻为中心的传播树。
    - **根节点**： 代表一条新闻。
    - **叶子节点**： 代表在Twitter上转发了这条新闻的用户。
    - **边**： 有两种类型：
        1.  用户和新闻之间的边：表示用户转发了该新闻。
        2.  用户和用户之间的边：表示用户A转发了用户B关于这条新闻的推文（即A是通过B看到这条新闻的）。

#### 数据集详情：
- **来源**： 基于两个知名的假新闻核查平台构建：
    - **Politifact**： 政治新闻领域。
    - **Gossipcop**： 娱乐八卦新闻领域。
- **规模**：

    | 数据集 | 图数量 | 假新闻数量 | 总节点数 | 总边数 | 平均每图节点数 |
    | :--- | :--- | :--- | :--- | :--- | :--- |
    | Politifact | 314 | 157 | 41,054 | 40,740 | 131 |
    | Gossipcop | 5,464 | 2,732 | 314,262 | 308,798 | 58 |

- **节点特征**： 提供了四种类型的用户节点特征：
    1.  **bert (768维)**： 使用预训练的BERT模型编码的用户特征。
    2.  **spacy (300维)**： 使用spaCy的word2vec模型编码的用户特征。
    3.  **profile (10维)**： 从Twitter用户个人资料中提取的特征（如粉丝数、注册时间等）。
    4.  **content (310维)**： 上述`spacy`特征和`profile`特征的组合。

#### 数据获取与使用：
- **便捷方式**： UPFD数据集已经被集成到两个主流的图深度学习库中：
    - **PyTorch Geometric (PyG)**： 可以直接使用`torch_geometric.datasets.UPFD`来加载。
    - **Deep Graph Library (DGL)**： 同样有内置的数据加载器。
    这是最推荐的方式，因为它自动处理了数据下载和预处理。
- **手动下载**： 如果手动安装本仓库，需要从提供的Google Drive链接下载数据，并解压到指定目录。

### 2. 模型

这个仓库实现了多种基于GNN的图分类模型，所有模型代码都在 `/gnn_model` 目录下。

**核心模型列表**：

1.  **GNN-CL**： 结合了持续学习，旨在解决模型在新数据上学习时的“灾难性遗忘”问题。
2.  **GCNFN**： 专门为假新闻检测设计的图卷积网络模型。
3.  **BiGCN**： 双向图卷积网络，同时捕捉新闻传播的“自顶向下”（从新闻到用户）和“自底向上”（从用户到新闻）的模式。
4.  **UPFD-GCN**： 标准的图卷积网络，作为强大的基线模型。
5.  **UPFD-GAT**： 图注意力网络，可以学习节点之间关系的重要性权重。
6.  **UPFD-SAGE**： 图采样与聚合模型，适用于大规模图，能有效捕捉邻居节点的信息。

**重要提示**： 由于整个框架基于PyG，你可以非常方便地将其他任何PyG支持的图分类模型（如GIN, HGP-SL等）应用到UPFD数据集上。

### 3. 如何参考和使用

如果你想在自己的研究或项目中使用这个仓库，建议遵循以下步骤：

#### A. 快速开始和复现
- **CodeOcean胶囊**： 作者提供了一个CodeOcean胶囊，可以一键复现结果，无需手动配置环境。这是验证模型性能最快的方式。
- **使用PyG/DGL**： 如果你想在自己的代码中快速使用数据集，最推荐的方式是直接通过PyG或DGL加载UPFD数据集，然后结合仓库中的模型代码进行训练。

#### B. 引用
如果你使用了这个仓库的数据集或代码，**必须引用**其原始论文：

```bibtex
@inproceedings{dou2021user,
  title={User Preference-aware Fake News Detection},
  author={Dou, Yingtong and Shu, Kai and Xia, Congying and Yu, Philip S. and Sun, Lichao},
  booktitle={Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year={2021}
}
```

#### C. 贡献
作者欢迎社区贡献：
- **提交新模型**： 你可以将自己的模型代码、超参数和结果通过**创建Pull Request**的方式提交。经过验证后，你的模型会被添加到仓库中。
- **更新基准**： 新的SOTA结果会被更新到相关的基准平台（如PaperWithCode）。

### 总结

这个仓库提供了一个**标准化的假新闻检测研究平台**，其核心价值在于：
1.  **高质量数据集 (UPFD)**： 一个结构清晰、特征丰富、已被主流库采纳的基准数据集。
2.  **多种基线模型**： 实现了多个重要的GNN模型，方便研究者进行公平比较。
3.  **良好的可扩展性**： 基于PyG，易于集成新模型和进行实验。

对于研究者来说，这是一个非常理想的起点，可以专注于模型创新，而无需花费大量精力在数据构建上。

---

## 如何适配题目要求
这个代码库和数据集是完成你课题的**绝佳基础**。它几乎是为你的任务要求量身定制的。下面我们来具体分析如何利用它来完成课题的各个部分。

### 总体评估：这个代码库与课题的匹配度

**匹配度非常高。** 你的课题要求是“欺诈检测”，而该代码库专门解决“虚假信息（谣言）检测”，这是欺诈检测在社交网络中的核心应用。它直接提供了你任务b）所需的数据、特征和模型框架，并为任务a）和c）提供了坚实的基础。

---

### 具体如何利用代码库完成课题任务

#### 任务 a）可视化用户之间的社交关系

这个代码库的UPFD数据集本身就是**传播图**，可视化这些图是直接且有意义的第一步。

**你可以直接利用代码库做以下可视化：**

1.  **基础网络结构可视化**：
    - 使用 `NetworkX` 或 `PyG`/`DGL` 的内置功能，绘制几个代表性的新闻传播图（一个真新闻图，一个假新闻图）。
    - **可视化重点**：
        - **节点颜色**： 将根节点（新闻）标为一种颜色（如红色），用户节点标为另一种颜色（如蓝色）。甚至可以进一步，根据用户是否是“关键传播者”（如高PageRank值）来区分颜色。
        - **节点大小**： 根据用户的度（连接数）或PageRank值设置节点大小，直观展示核心传播者。
        - **图布局**： 使用层次化布局（如 `nx.spring_layout` 或 `nx.kamada_kawai_layout`）来清晰显示以新闻为根节点的树状传播结构。

2.  **网络统计特性可视化**：
    - 代码库没有直接提供，但你可以基于图数据轻松计算并绘制：
        - **度分布图**： 分别绘制真假新闻传播图中用户的度分布曲线。正常信息的传播可能更符合幂律分布，而谣言可能由大量低度用户（水军）推动。
        - **图直径/平均路径长度**： 比较真假新闻传播的“深度”。谣言可能传播得更深更广。
        - **社区结构**： 使用社区发现算法（如Louvain）对用户进行聚类，然后用不同颜色标注社区，观察谣言是否在特定社区内爆发式传播。

**示例代码思路：**
```python
import networkx as nx
import matplotlib.pyplot as plt
from torch_geometric.datasets import UPFD

# 加载数据集
dataset = UPFD(root='./data', name='politifact', feature='content')

# 取一个图为例（例如第一个图）
data = dataset[0]
# 将PyG的Data对象转换为NetworkX图
G = nx.Graph()
# 添加节点和边...
# ... (这里需要将PyG的edge_index转换为NetworkX可用的边列表)

# 绘制网络图
plt.figure(figsize=(10, 8))
pos = nx.spring_layout(G)
# 区分新闻节点和用户节点
node_color = ['red' if i == 0 else 'blue' for i in range(data.num_nodes)] # 假设第一个节点是新闻
nx.draw(G, pos, node_color=node_color, node_size=50, with_labels=False)
plt.title(f"News Propagation Network (Label: {'Fake' if data.y.item() else 'True'})")
plt.show()
```

---

#### 任务 b）设计机器学习模型识别虚假信息

**这是该代码库的核心价值所在。你不需要从零开始，而是可以在一个很高的起点上进行。**

**1. 特征工程（代码库已为你完成大部分）：**
- **社交关系特征**： 图结构本身（邻接矩阵）就是最强的社交关系特征，GNN模型会自动学习。
- **用户特征**： 代码库提供了4种现成的节点特征（`bert`, `spacy`, `profile`, `content`），你可以直接使用或进行组合。这涵盖了“用户属性”。
- **传播行为特征**： 图的拓扑性质（如度中心性、聚类系数）可以作为额外的节点特征，这些可以从图中提取。

**2. 模型设计（直接使用和对比）：**
- **基线模型**： 代码库提供了6个现成的GNN模型（GCN, GAT, GraphSAGE, BiGCN等）。你可以直接运行这些模型，得到它们在数据集上的性能作为你的**基线结果**。这是你项目成果的坚实基础。
- **模型改进（你的创新点）**： 在现有模型基础上，你可以尝试以下**简单但有效的改进**，这将成为你项目的亮点：
    - **特征融合**： 尝试不同的节点特征组合（例如，将`profile`特征和`spacy`特征拼接），观察哪种特征组合对检测最有效。
    - **模型集成**： 将GCN、GAT等模型的预测结果进行投票或加权平均，看是否能提升性能。
    - **添加传统特征**： 在GNN模型的最后分类层之前，融入一些手工提取的图级特征（如整个图的节点数、边数、密度等），让模型同时学习局部和全局信息。

**3. 模型评价（标准流程）：**
- 代码库已经采用了标准的机器学习评价流程：**数据集划分（训练/验证/测试集）**。
- 你可以直接报告以下指标，这些都是学术界的标准：
    - **准确率（Accuracy）**
    - **精确率（Precision）**： 在所有被预测为假的新闻中，真正是假的比例。（重点关注）
    - **召回率（Recall）**： 在所有真正的假新闻中，被模型成功找出来的比例。（重点关注）
    - **F1-Score**： 精确率和召回率的调和平均数。
    - **AUC-ROC曲线**： 综合衡量模型性能。

---

#### 任务 c）分析传播网络的异同

在完成模型训练和可视化后，这个分析就是水到渠成的事。

**你可以从以下维度对比真假新闻的传播网络：**

1.  **网络结构特性**：
    - **图规模**： 假新闻的传播图是否平均节点数更多（病毒式传播）？还是更少（局限于小圈子）？
    - **密度**： 假新闻传播图中用户之间的互动（用户-用户边）是否更密集？（可能表明有组织的转发）
    - **深度**： 假新闻的传播路径是否更长？（可能表明经过多次转发）
    - **中心化程度**： 假新闻的传播是否更依赖于少数几个关键节点（大V）？还是更加去中心化？（用水军矩阵转发）

2.  **用户行为特性**：
    - **用户活跃度**： 传播假新闻的用户是否是新建账号？他们的平均粉丝数/关注数比是否异常？
    - **传播速度**： 通过节点时间戳（数据集提供`*_id_time_mapping.pkl`），可以分析假新闻从发布到引爆的时间模式，是否比真新闻更快？

**如何呈现：**
- 制作**对比表格**，列出上述各个维度在真假新闻群体上的平均值，并进行简单的统计检验（如T检验）说明差异是否显著。
- 将任务a）中的可视化结果并排列出，直观展示差异。

---

### 总结：你可以在代码库基础上做什么？

| 课题任务 | 代码库提供的基础 | 你可以做的创新和扩展 |
| :--- | :--- | :--- |
| **a) 可视化** | 结构化的图数据（节点、边） | 1. 实现更美观、信息量更大的可视化（如使用PyVis或Gephi）。<br>2. 计算并可视化网络统计指标（度分布、路径长度等）。 |
| **b) 模型设计** | 1. 标准数据集<br>2. 多种现成GNN模型<br>3. 丰富的节点特征 | 1. **系统性的模型对比**：公平地比较所有模型并分析其优劣。<br>2. **简单的模型改进**：如特征融合、模型集成。<br>3. **引入外部知识**：如结合情感词典分析帖子内容情感。 |
| **c) 对比分析** | 带有标签的图数据 | 1. **深入的网络测量**：超越简单可视化，进行定量的网络科学分析。<br>2. **关联模型性能**：分析为什么某些网络特征的假新闻更难被检测，从而解释模型的局限性。 |

**给你的核心建议：**

**不要只满足于复现代码库的结果。** 你的课程项目价值在于 **“在现有工作基础上的探索和分析”**。

1.  **核心工作**： 先确保能成功运行代码库中的1-2个主要模型（如UPFD-GCN和UPFD-GAT），得到可复现的基准结果。
2.  **创新点/亮点**： 然后选择上述表格中“你可以做的创新和扩展”里的一到两点进行深入。例如，**重点做一个“不同节点特征对模型性能影响”的对比实验**，这个工作量适中且分析清晰，很容易出彩。

如果你能完成“复现+对比分析+有深度的讨论”，你的项目报告将会非常出色。你现在对哪个部分最感兴趣，或者觉得哪一部分实现起来可能有困难？我们可以从那里开始详细讨论。
